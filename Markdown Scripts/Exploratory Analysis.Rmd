---
title: "Faculty Engagement EDA"
author: "William Morgan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', fig.dim = c(3.5,3.5))

libs <- c('readxl', 'tidyverse', 'data.table', 'gridExtra')
lapply(libs, library, character.only = TRUE)
```

## __1. Import and Check Structure__

```{r, echo = F}
forum <- read_excel('Data/20180405 Fac Engagement.xlsx', sheet = 1)
names(forum) <- str_to_lower(names(forum))
```

__Goals:__

  - Import data

  - Find important variables

  - Check if cleaning needs to be done  

__Preliminary thoughts:__

  - `course_year`, `cem_unique`, `cour_st_dt`, `cour_end_dt` appear redundant or
  unnecessary
  
  - rename `sln`, `term_session` to `class_nbr`, `session_code` for consistency
  
  - insert '|' between subject and catalog number in `course` for consistency
  
  - `acad_career` is a student-level variable and may not make sense to use
  at this granularity
  
  - This includes graduate courses, which for now I'll just get rid of 
  
__Things to inspect:__
  
  - what is the difference between `acad_group` and `acad_org`? 
  
    - `acad_group` is kind of like college but not exactly? full data has weird 
    cross tabs 
    
    - `acad_org` appears to be the department
    
  - what is the distribution of enrollment totals?
  
  - any courses from campuses outside the normal group? (Poly, West, Tempe, DT, ASUO)
  
  - how complete is the feedback data?
  
__Update before moving on:__

  - Drops:  
  
    - Graduate courses and missing courses
    
    - `course_year`, `cem_unique`, `cour_st_dt`, and `cour_end_dt` variables
    
    - Rename `sln` and `term_session`
    
    - Recreate `course` based on previous work

    
```{r}
forum <- forum %>%
  filter(course != '-' & as.numeric(str_sub(course, 4, 6)) < 500) %>%
  select(-c(cour_st_dt, cour_end_dt, cem_unique)) %>%
  rename(session_code = term_session) %>%
  mutate(subject = str_sub(course, 1, 3), 
         catalog_nbr = str_sub(course, 4, 6),
         course = paste(subject, catalog_nbr, sep = '|'),
         enrl_total = pass_ct + wdwn_ct + fail_ct) 

```

***

## __2. Further inspection__

#### __What's the distribution of enrollment totals?__

```{r prelim enrollment totals, echo = FALSE, warnings = F}
ggplot(forum, aes(enrl_total)) +
  geom_histogram() + 
  ggtitle("Overall Enrollment Totals") +
  theme(plot.title = element_text(hjust = 0.5))
```

Okay, so a handful of courses with super high enrollment are throwing off this 
graph, so let's figure out what these courses are and redo the graph without them
to get a better understanding of the majority. We're not really interested in how
many students are in these courses, just what the courses are

```{r list high enrollment classes, echo = FALSE}
forum %>%
  filter(enrl_total > 300) %>%
  group_by(course) %>%
  arrange(desc(enrl_total)) %>%
  filter(row_number() == 1) %>%
  select(course, enrl_total)

```

These are all intro freshman courses, so everything looks to be as expected there.
Now let's check out low enrollment courses:

```{r list low enrollment classes, echo = FALSE}
forum %>%
  filter(enrl_total < 5) %>%
  group_by(course) %>%
  filter(row_number() == 1) %>%
  arrange(subject) %>%
  select(course)
```

These courses are going to be a pain in the butt to filter through
because a lot of them appear to be topic courses or internships (courses with 
catalog_nbr of 384, 394, or 494 are generally specially designed courses). It would
probably be a good idea to merge `descr` and `descr2` from the peoplesoft tables
to give us more info.

For now, let's just get rid of any courses with less than 5 students because
__a.)__ it isn't that many courses and __b.)__ we know that some of those are irregularly
taught courses that are probably irrelevant to the analysis

```{r plot enrollment with filters, echo = FALSE, warnings = F}
forum %>%
  filter(enrl_total > 5) %>%
  ggplot(aes(enrl_total)) + 
  geom_histogram(binwidth = 20)
```

Before we move on, I'm going to assume that this super-low enrollment courses
will actually turn out to be irrelevant for the study, so I will drop them entirely
from the data set. To recap, the cumulative list of drops I've made is:

- Graduate courses and missing courses

- Courses with less than 5 students enrolled

```{r}
forum <- forum %>% filter(enrl_total >= 5)
```

#### __Campus/Location Variable__

__ THIS SECTION IS NOW UNNECESSARY DUE TO CHANGES IN THE DATA __


In the full data ASUO is designated as a unique location and observations having
"ASUONLINE" `location` values should (for the most part) only have "ONLNE" as
their `campus`. In other words, online students have their own campus that is different
from Tempe, Poly, etc. 

For some reason, this data seems to have a variety of values for campus despite
the fact that there should only be one campus in the data. I don't know what the
cause of this is and it could definitely be the case that I'm interpreting something
wrong on the full_data end. To illustrate, here's a cross-tab of location and campus
in the forum data:

```{r location campus tab, echo = FALSE, eval = F}
table(forum$location, forum$campus)
```

I won't do anything with this for now because it really isn't that big of a deal,
but whatever is causing this needs to be understood

#### __Feedback Data Completeness__

When I initially glanced at the data, it seemed like there were a ton of missing
values for the variables around student-course reviews. Let's check first if there
were any missing values for `num_evals_expected`. We shouldn't have any, hopefully.

```{r number of courses missing surveys, echo = FALSE}
forum %>%
  filter(is.na(num_evals_expected)) %>%
  nrow()
```

Okay, so about 2100 courses have missing values for `num_evals_expected`. It
is not included here but these courses also have missing `responserate`, so I will
just assume that these guys are also missing the average response for each of the questions.

Let's investigate a little more into these courses - is it limited to a specific
time frame? course? department? (for the moment we assume that `acad_org` is the
department; still working on confirming this)

```{r, echo = FALSE}
forum %>%
  filter(is.na(num_evals_expected)) %>%
  group_by(strm) %>%
  tally() %>%
  ggplot(aes(strm, n)) + 
  geom_bar(stat = 'identity') + 
  ggtitle("Missing Surveys by STRM") +
  theme(plot.title = element_text(hjust = 0.5))
  
```

It is probably reasonable to assume that the missing values from earliers terms
are just flat out missing from the warehouse, but I'm not sure what is going on
with the more recent terms. For now, we'll just drop the course-sections with
missing `expectedsurveys` and move on to checking out `responserate`. Just as
a quick recap, the current list of drops is:

- graduate courses or missing courses (~2100)

- courses with less than 5 students (~700)

- courses with missing surveys (~2100)

```{r delete missing expectedsurveys, echo = FALSE}
forum <-  forum %>% filter(!is.na(num_evals_expected))
```

Onto the graphing:

```{r plot response rate distro, echo = FALSE}
ggplot(forum, aes(num_evals_taken / num_evals_expected)) +
  geom_histogram() +
  ggtitle("Response Rate Distribution") +
  theme(plot.title = element_text(hjust = .5))
```

This looks pretty good, no reason for concern. Since most of this looks fine, 
let's just move on to some feature engineering before we get to modeling

***

## __3. Faculty Posts__

We want to investigate the distribution of the faculty postings. In particular,
we look at `num_fac_ta_posts`, `total_len_fac_ta_posts`, and `num_fac_ta`

```{r, echo = F}
forum %>%
  filter(num_fac_ta < 8) %>%
  group_by(num_fac_ta) %>%
  tally()
```

So it turns out that there are a lot of courses that don't have any faculty. We
need to drop those courses for now until we have an answer as to why this is the case

```{r}
forum <- filter(forum, num_fac_ta > 0)
```

Now that that is out of the way, let's look at at the distributions for the other
two variables of interest:

```{r, echo = F, fig.dim= c(10, 3.5)}
plotHist <- function(data, column, title){
  data %>%
    ggplot(aes(column)) +
    geom_histogram() + 
    ggtitle(title) +
    theme(plot.title = element_text(hjust = .5))
}

num <- plotHist(forum, forum$num_fac_ta_posts, "Number of faculty posts")
len <- plotHist(forum, forum$total_len_fac_ta_posts, "Length of faculty posts")

grid.arrange(num, len, nrow = 1)
rm(num, len)
```

There are some huge outliers that are throwing off the graphs. To condense this
slightly, let's drop anything above the 95th quantile for the faculty post length.
This is done assuming that the reason for these crazy high totals is because an
instructor might post fat blocks of text describing an assignment. These observations
are less valuable because they are less of a representation of faculty engagement
and more of how the instructor uses the blackboard shell. 

We leave in observations with really high faculty post counts because that is 
likely indicative of instructors who reply to a lot and post often, which is 
exactly what we want to identify.

```{r, fig.dim = c(10, 3.5)}
forum <- forum %>%
  filter(total_len_fac_ta_posts <= quantile(total_len_fac_ta_posts, .95))

plotHist <- function(data, column, title){
  data %>%
    ggplot(aes(column)) +
    geom_histogram() + 
    ggtitle(title) +
    theme(plot.title = element_text(hjust = .5))
}

num <- plotHist(forum, forum$num_fac_ta_posts, "Number of faculty posts")
len <- plotHist(forum, forum$total_len_fac_ta_posts, "Length of faculty posts")

grid.arrange(num, len, nrow = 1)
rm(num, len)

```

Distributions are stil ultra skewed - let's get a numeric summary real quick and
keep it for later

```{r}
summary(forum$num_fac_ta_posts)
summary(forum$total_len_fac_ta_posts)
```


***

## __4. Missing Values__

This will be a relatively short section; we just want to check out which variables
have missing values and guess why that might be. More than likely we will have
to go back to Mike for an explanation. Any variables with missing values will
be dropped

```{r missing value tally}
sapply(forum, function(x) sum(is.na(x)))
```



```{r drop missing}
forum <- forum %>%
  filter_all(all_vars(!is.na(.)))
```

Summary of drops so far:

- graduate courses or missing courses (~2100)

- courses with less than 5 students (~700)

- courses with missing surveys (~2100)

- 0 faculty/ta (~600)

- faculty length outliers (~200)

- missing values (~5?)

***

## __5. Feature Engineering__

This section is probably just going to be condensing a couple of variables (like
"faculty posted in week X") and maybe coming up with some extra dependent variables

Possible ideas:

  - change num_stu_with_posts to proportion
  
  - condense survey questions into faculty/design split

  - indicator for having posted in first or last week?
  
What is the gpa of students who withdraw??? It should be 0   
  
New find: the question responses are not numeric and have to be changed

I'm actually just going to drop all the C session courses cause they represent
like none of the sample

```{r new variables}
# Grab question names
questions <-  forum %>%
  select(starts_with('q_')) %>%
  names()

# Force questions to numeric 
forum <- forum %>%
  mutate_at(questions, as.numeric)

# Add new variables
forum_cleaned <- forum %>%
  mutate(prop_stu_posted = num_stu_with_posts / enrl_total,
         avg_gpa = sum_gpa / enrl_total,
         wdrw_rate = wdwn_ct / enrl_total,
         instr_score = (q_responded + q_present + q_feedback) / 3,
         design_score = (q_success + q_prepared + q_presentations + q_navigate) / 4,
         posts_per_student = num_stu_posts / enrl_total,
         posts_per_fac = num_fac_ta_posts / num_fac_ta,
         pass_rate = pass_ct / enrl_total,
         avg_fac_post_len = total_len_fac_ta_posts / num_fac_ta_posts,
         upper_division = if_else(
           as.numeric(str_sub(course, 5, 7)) >= 300, 1, 0),
         fac_posts_boc = num_fac_posts_wk0 + num_fac_posts_wk1 + num_fac_posts_wk2,
         fac_posts_eoc = num_fac_posts_wk6 + num_fac_posts_wk7 + num_fac_posts_wk8,
         pass_rate = pass_ct / enrl_total,
         response_rate = num_evals_taken / num_evals_expected) %>%
  rename(course_id = myasu_course) %>%
  select(course_id, session_code, pass_rate, avg_gpa, wdrw_rate,
         enrl_total, response_rate, has_hallway,
         fac_posts_boc, fac_posts_eoc, total_len_fac_ta_posts,
         instr_score, design_score, posts_per_fac,
         posts_per_student, avg_fac_post_len, upper_division) %>%
  filter(session_code %in% c("A", "B"))

# Do a final check on missing values
#sapply(forum_cleaned, function(x) sum(is.na(x)))

write_csv(forum_cleaned, "Data/forum_cleaned.csv")
```

Final summary of drops (we started with n = 8916)

- graduate courses or missing courses (~2100)

- courses with less than 5 students (~700)

- courses with missing surveys (~2100)

- 0 faculty/ta (~600)

  - student data on these is still good in case we need/want it at some point

- faculty length outliers (~200)

- missing values (~5?)

- session C courses (~25)

Final tally: N = 3237


---
title: "Engagement EDA"
author: "William Morgan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center', fig.dim = c(3.5,3.5))

libs <- c('readxl', 'tidyverse', 'data.table', 'gridExtra', 'stringr', 'magrittr')
lapply(libs, library, character.only = TRUE)
```

## Purpose:

Run preliminary correlational analyses to uncover possible relationships
between student outcomes and various measures of faculty engagement. This will
inform our approach to modeling later.

Forms of engagement to inspect:

  - Presence of a Hallway Conversation board
    
    - Blackboard discussion forums sometimes have boards to emulate hallway
    conversations. These boards are meant to imitate natural discussion that
    would happen between students and instructors between classes
    
  - Faculty Post Consistency
  
  - Post Quantity
  
Outcomes of interest:

  - Student Perception of Faculty Engagement (`instr_score`)
  
    - These scores come from course evaluations; there are three questions
    pertaining to faculty presence and engagement which we average into
    a single score
    
  - Student Posts (`posts_per_student`)
  
    - The average number of posts per student throughout the duration of the course
    
  - Student Posts Consistency (`stu_post_consistency`)
    
  - Student Grades (`avg_grade`)
  
    - Average grade received in a course-section

## General Outline

The goal is to understand which features correlate most with the several
outcomes. As a first pass we'll create a correlation heatmap relating the continuous features
to each of the outcomes. This will give us some basic insight on any apparent linear
relationships. Next we'll move on to plotting the features individually to get a 
sense of any nonlinear relationships. In particular, we are looking for evidence
favoring the inclusion of polynomial terms in a regression. We'll conclude with
similar plots for the categorical variables (i.e. plotting a feature against a
particular outcome).

Before moving on, let's preview the data to remind ourselves what we'll be working
with.

```{r, include = FALSE}
source("Code/Sample Selection.R")

```

```{r}
str(forum)
```

***
 
## Correlation Heatmap

```{r, fig.dim = c(7, 5)}
forum_mat <- forum %>%
  select_if(is.numeric) %>%
  select(order(colnames(.))) %>%
  as.matrix

# Create correlation matrix and grab lower half
cormat <- round(cor(forum_mat), 2)
cormat[upper.tri(cormat)] <- NA

# reshape for plotting
cormat <- melt(cormat, na.rm = TRUE) %>%
  rename(correlation = value)


heatmap <- ggplot(cormat, aes(Var1, Var2, fill = correlation)) + 
           geom_tile(color = 'white') +
           scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white',
                                midpoint = 0, limit = c(-1, 1)) +
           theme(axis.text.x = element_text(angle = 45,
                                            vjust = 1,
                                            size = 10,
                                            hjust = 1),
                 axis.title.x = element_blank(),
                 axis.title.y = element_blank(),
                 axis.ticks = element_blank(),
                 panel.border = element_blank(),
                 panel.background = element_blank(),
                 legend.justification = c(1,0),
                 legend.position = c(.5, .7),
                 legend.direction = 'horizontal')

# add labels to items with abs_val greater than .15
heatmap + 
  geom_text(data = cormat[abs(cormat$correlation) > 0.1, ],
            aes(Var1, Var2, label = correlation),
            color = 'black',
            size = 3)
```

### Discussion

`instr_score` appears to be unrelated with every variable we
were considering to include in a regression model. This doesn't mean we should 
throw it out necessarily, but it does indicate that is has a very very weak linear
association with all other variables.` posts_per_student` has
a somewhat negative relationship with the number of students in the course and
a slightly negative correlation with the proportion of faculty posts in the
first two weeks (`prop_posts_boc`) but for the most part the situation is the
same. `avg_grade` unfortunately appears to be just as uncorrelated as the other
outcomes. We'll have to move on to doing more general plots to uncover something.
Just like the others, `stu_post_consistency` does not seem to have any strong
correlations with the explanatory variables.


***

## Two-way plots

```{r}
scatter <- function(x, y, title) {
  forum %>%
    ggplot(aes(unlist(.[, x]), unlist(.[, y]))) +
    geom_point(alpha = 0.3) +
    geom_smooth(method = 'loess') +
    labs(x = x,
         y = y,
         title = title) +
    theme(plot.title = element_text(hjust = 0.5))
}

cont_vars <- c("avg_fac_post_len", "enrl_total", "fac_post_consistency",
               "posts_per_fac", "prop_posts_boc", "prop_posts_eoc")
```

### __Instructor Score plots__

```{r, fig.dim = c(6, 4)}
for (i in seq_along(cont_vars)) {
  print(scatter(cont_vars[i], "instr_score", paste(cont_vars[i], "vs. Instructor Score")))
}

```
#### Discussion

  - Surprisingly, each of the six variables appears to have practically no effect
  on the instructor evaluation scores

### __Average Grade__
```{r, fig.dim = c(6, 4)}
# Grade Plots
for (i in seq_along(cont_vars)) {
  print(scatter(cont_vars[i], "avg_grade", paste(cont_vars[i], "vs. Average Grade")))
}
```
#### Discussion

  - Like the previous outcome, none of these plots suggest that the variables we 
  thought to be important will be relevant in predicting grade.
  
### __Posts per Student__
```{r, fig.dim = c(6, 4)}
for (i in seq_along(cont_vars)) {
  print(scatter(cont_vars[i], "posts_per_student", paste(cont_vars[i], "vs. Posts per Student")))
}
```

#### Discussion

  - Disappointingly, none of the variables here seem to be strongly related
  to the number of posts per student. This seems to be completely opposite to
  our expectations, but at the very least we now have some reason to start looking
  for other possible explanations
  
## __Student Post Consistency__
```{r, fig.dim = c(6, 4)}
for (i in seq_along(cont_vars)) {
  print(scatter(cont_vars[i], "stu_post_consistency", paste(cont_vars[i], "vs. Student Post Consistency")))
}
```

#### Discussion

  - It appears that for very low enrollment courses student post consistency
  is higher than average. Other than this relatively small finding, the rest
  of the variables do not appear to show any significant relation with student
  post consistency.
  
***

## Binary Variable Exploration

Up until this point we've ignored the three binary variables in the data - 
`has_hallway`, `session_a`, and `upper_division`. We defined the first earlier,
and the last should be self-explanatory, but the second indicator tells us if the
course-section occurred during the first 8-week session of the semester or the
second. 

Now that we have practically abandoned all hope with the continuous variables, 
we need to see if the same pattern is going on with the binary variables.


```{r}
box <- function(x, y, title) {
  forum %>%
    ggplot(aes(unlist(.[, x]), unlist(.[, y]))) +
    geom_boxplot() +
    labs(x = x,
         y = y,
         title = title) +
    theme(plot.title = element_text(hjust = 0.5))
}
```


### __Instructor Score__
```{r, fig.dim = c(6, 4)}
for (i in c("has_hallway", "session_a", "upper_division")) {
  print(box(i, "instr_score", paste(i, "vs Instructor Score")))
}
```

### __Average Grade__
```{r, fig.dim = c(6, 4)}
for (i in c("has_hallway", "session_a", "upper_division")) {
  print(box(i, "avg_grade", paste(i, "vs Average Grade")))
}
```

### __Posts per Student__
```{r, fig.dim = c(6, 4)}
for (i in c("has_hallway", "session_a", "upper_division")) {
  print(box(i, "posts_per_student", paste(i, "vs Posts per Student")))
}
```

### __Student Post Consistency__
```{r, fig.dim = c(6, 4)}
for (i in c("has_hallway", "session_a", "upper_division")) {
  print(box(i, "posts_per_student", paste(i, "vs Student Post Consistency")))
}
```

#### Discussion

Based on these plots, it is fair to say that we have evidence against using 
any of these variables to explain variation in the outcomes. None of the box 
plots revealed noticeable differences in outcomes between the levels of the binary
indicator, so it is unlikely that they will be useful in a regression.

***

## Conclusion

These are rather disappointing results, but this is not necessarily the end of the
line. We can still move forward with some modeling to see if any sort of signal 
can be extracted from these variables and if all else fails we can revisit 
the data extraction and the feature engineering.















  
  